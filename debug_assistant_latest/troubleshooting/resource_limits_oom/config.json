{
    "api-agent": {
        "model": "llama3.1:70b",
        "embedder": "nomic-embed-text",
        "clear-knowledge": true,
        "new-run": true,
        "init-agent": true,
        "knowledge": [
            "https://learnk8s.io/troubleshooting-deployments"
        ]
    },
    "debug-agent": {
        "llm-source": "Ollama",
        "model": "llama3.1:70b",
        "instructions": [
            "You are taking actions to fix problems with a kubernetes cluster."
        ],
        "api-key": ""
    },
    "knowledge-prompt": {
        "problem-desc": "The pod is repeatedly being killed (OOMKilled) because its memory limit (50Mi) is too low for the application's memory requirements (~80MB).",
        "system-prompt": "Give specific commands to fix this issue. If modifying file contents is necessary, use the sed command to achieve this. If providing a file path, make sure to keep the full file path.",
        "additional-directions": "Check pod events and logs to identify OOMKilled status, then increase memory limits appropriately."
    },
    "debug-prompt": {
        "additional-directions": "If any deployment files are modified, reapply the deployment to the cluster."
    },
    "relevant-files": {
        "deployment": [
            "resource_limits_oom.yaml"
        ],
        "application": [
            "server.py"
        ],
        "dockerfile": true
    },
    "test-name": "resource_limits_oom",
    "test-directory": ""
}
